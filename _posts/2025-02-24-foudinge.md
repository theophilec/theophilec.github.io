---
layout: post
title: Mapping the French Culinary Universe
date: 2025-02-27
description: Creating a knowledge graph of restaurants featured in lefooding.com reviews using `outlines` and `gpt4o-mini`.
categories: llm food
---

For French restaurant intel, [lefooding.com](https://lefooding.com) is the definitive data source. Their anonymous critics conduct systematic reviews of establishments across France (and now Belgium), documenting their findings in a witty - if peculiar - style. Turns out we can use them to map France's culinary universe.

Explore the universe in this graph ([Direct link to the visualization](https://ouestware.gitlab.io/retina/1.0.0-beta.4/#/graph/?url=https%3A%2F%2Fgist.githubusercontent.com%2Ftheophilec%2F351f17ece36477bc48438d5ec6d14b5a%2Fraw%2Ffa85a89541c953e8f00d6774fe42f8c4bd30fa47%2Fgraph.gexf&r=x&sa=re&ca[]=t&ca[]=ra-s&st[]=u&st[]=re&ed=u)). Purple nodes are restaurants and green nodes are people. Larger nodes have a higher degree. Click around to see neighbors and discover components.
<iframe
  width="800"
  height="600"
  src="https://ouestware.gitlab.io/retina/1.0.0-beta.4/#/embed/?url=https%3A%2F%2Fgist.githubusercontent.com%2Ftheophilec%2F351f17ece36477bc48438d5ec6d14b5a%2Fraw%2Ffa85a89541c953e8f00d6774fe42f8c4bd30fa47%2Fgraph.gexf&r=v&sa=re&ca[]=t&ca[]=ra-s&st[]=u&st[]=re&ed=u"
  frameBorder="0"
  title="Retina"
  allowFullScreen
></iframe>

Some interesting insights from the graph:
- Look for Septime or Ducasse. Each of these has helped raise chefs that go on to be chefs in other restaurants (including their own).
- Explore around Caillebotte and find all the sister restaurants listed [online](https://www.lapantruchoise.com/).

> Share your insights and I'll add them here!

# What am I looking at ?

The graph above combines information about serveral thousand entities (people and restaurants) and relations between them from 1 800 publicly available lefooding.com reviews.

For instance, take this review of _Grenat_:

> À l’enseigne de Grenat, Antoine Joannier et Neil Mahatsry ont le rouge aux joues et aux murs. Après avoir officié à La Brasserie Communale, où ils se sont rencontrés, les deux compères font désormais feu de tout bois en plein centre de Marseille, où Antoine veille au grain autour des tables en bois blond, convoyant les plats que Neil embrase à tout-va depuis l’âtre derrière le comptoir. Des huîtres aux pièces viandardes, en passant par la verdure et le poisson, tout y flambe, fume, grille, cuit à l’étouffée ou se voit marqué au fer à repasser brocanté. Dans nos assiettes ce midi-là, une marinière de moules et palourdes à la flamme, dopée par un bouillon de bœuf et de la ‘nduja, suivie d’un torride tentacule de poulpe accompagné de chou frisé grillé et d’une tapenade d’olives de Kalamata fumée… Même les desserts y passent, comme cette glace au lait fermenté et encore fumé, flanquée d’une ganache au chocolat blanc caramélisée et toppée d’un granola aux noix. Du mercredi au vendredi soir, le ton et les prix montent d’un cran pour faire place au menu en huit temps.

Beyond the merits of the food and ambiance, it gives valuable information about the people who work at Grenat (Antoine Joannier and Neil Mahatsry), about their roles and where they worked before. This information is part of the graph:

![Grenat in the graph](/assets/img/grenat.png)

All the code used can be found on [Github](https://github.com/theophilec/foudinge).

# Approach

The approach follows a straightforward process. For each restaurant review, we extract specific information (people, roles, relationships). Then, we combine the information into a graph, highlighting connected entities, components, ... The graph can then be visualized and analyzed. This differs from a RAG (Retrieval-Augmented Generation) approach. With RAG, we would embed reviews and let an LLM answer queries about the corpus (like "Where did Antoine Joannier and Neil Mahatsry meet before working at Grenat?"). While that would be possible, it's not our focus here (future work?).

The key challenge in our approach is ensuring extracted entities maintain a consistent structure. LLMs struggle with producing JSON according to a given schema. Simply asking a model via prompting to "give me valid JSON and nothing else" typically results in inconsistent formatting, extra text, or invalid structures.

Using the logits of a model, one can modify the sampling probabilities to enforce the generated tokens to build into valid JSON according to a given schema. OpenAI implements this in its API. When using an open model like Mistral-7B-v0.3 or Llama3.2-3B, we use `outlines` from [.txt](https://dottxt.co/). Both use a finite automaton approach like for applying a regular expression.

There is three steps in building the graph:

1. Get the data from lefooding.com
2. Extracting information from each review (inferring entities)
3. Building a graph
4. Making the visualization

The code used is available at [theophilec/foudinge](https://github.com/theophile/foudinge).

## 1. Get the data from lefooding.com

We first gather all review URLs from lefooding.com's directory by paginating through all listings. Then we scrape each review page for its title and text content. To prevent data loss from network failures, we implement asynchronous batch processing and store results in a SQLite database after each completed batch.

## 2. Inferring entities

For the Grenat review above, we aim at getting:

```
Person(
  name='Antoine Joannier',
  role='Host',
  previous_restaurants=['La Brasserie Communale']
)

Person(
  name='Neil Mahatsry',
  role='Chef',
  previous_restaurants=['La Brasserie Communale']
)
```

`outlines` is a library for constraining LLM output to a JSON schema (more generally a regular expression) using the logits. OpenAI also exposes such functionality through its API (which `outlines` wraps). We define the structure through a `pydantic` model:

```python
class Role(str, Enum):
    CHEF = "Chef"
    SOMMELIER = "Sommelier"
    SERVER = "Serveur"
    OWNER = "Propriétaire"

class Person(BaseModel):
    name: str
    role: Role
    previous_restaurants: list[str]

class Summary(BaseModel):
    people: list[Person]
```

with the following prompt template:
```python
def prompt_template(text, schema):
    return f"""
    Tu es un expert gastronomique basé sur l'IA. Tu es chargé d'extraire les informations suivantes de manière structurée d'une critique de restaurant.

    Pour chaque personne impliquée dans le restaurant, indique:

    1. Son nom, dans le champ "name".

    2. Son rôle, dans le champ "role". Choisis parmi les options suivantes : "Chef" (ceux qui cuisinent), "Sommelier" (ceux qui s'occupent des boissons), "Serveur" (ceux qui servent en salle), "Propriétaire" (propriétaire ou patron du restaurant), "Fournisseur" (ceux qui fournissent les produits : légumes, fruits, viandes, poissons, fruits de mer...) Attention, tous les rôles peuvent être tenus par un homme ou une femme.

    3. Les noms des restaurants dans lesquels il a travaillé précédemment, dans le champ "previous_restaurants" sous la forme d'une liste. Si aucun restaurant précédent n'est mentionné, n'inclus pas le champ. N'inclus pas d'information sur la localisation de ces restaurants.

    Attention à ne mentionner que des personnes impliquées dans le restaurant et pas des personnes mentionnées dans la critique (des célébrités, ...).

    Attention à n'inclure que les personnes présentes dans la critique. N'invente pas de personne fictive ni de placeholder ("anonyme", "personne fictive", ...).

    Texte de la critique à résumer :
        {text}

    N'inclut que les résultats aucune autre information ou explication.

    Ta réponse doit être structurée dans un format JSON valide:
        {schema}
    """
```

The syntax is then to take a compatible `model` and use the generator API in `outlines`:
```python
model = ...
generator = outlines.generate.json(model, Summary)
result = generator(prompt_template(text))
```
where, in the end, `result` is a `Summary` object.

Like `outlines`, I too am GPU poor. I tried several models on my M1 MBP, but opted for using a larger GPU, in one of two ways. First, I computed entities of a subset of reviews using the `mistralai/Mistral-7B-v0.3` model OVH's AI notebook (which give 200 euros free credit, i.e. 100+ hours of inference). Since the results were not great (and inference quite slow), I tried using `gpt4o-mini`'s structured generation API through `outlines`, which gave good results. The cost of inference on `gpt4o-mini` is tiny at < 1€ (including the almost 2k reviews and quite a bit of testing before).

> Future work: get an open model to work with the help of `outlines` (they have office hours, I am going to try to go to the next ones)!

I created [`foudinge-scrub`](https://github.com/theophilec/foudinge-scrub) as a small web app to help clean the entities to correct errors while maintaining the schemas. This was coded in 6 iterations using Claude 3.7 Sonnet, and is way beyond my web development skills. It has full text search (the more advanced search does not work). There is also a small script to detecting duplicates. There are still a few duplicates to fix, which I'll get around to.

## Visualization

The extracted entities are converted to a graph format and visualized using [gephi-lite](https://gephi.org/gephi-lite/). The spatialized graph - putting nodes with higher degrees more to the center - is hosted on Github Gist and rendered through [Retina](https://ouestware.gitlab.io/retina) in the iframe above.

> Note: I identified and reported an [issue](https://github.com/gephi/gephi-lite/issues/187) in gephi-lite where string escaping prevented proper Retina imports. This has been fixed in the main branch.
